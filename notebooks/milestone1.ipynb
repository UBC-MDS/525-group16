{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 16 Milestone 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import zipfile\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "url = \"https://api.figshare.com/v2/articles/14096681\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"../data/\"\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)\n",
    "files = data[\"files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 333 µs, sys: 113 µs, total: 446 µs\n",
      "Wall time: 399 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files_to_dl = \"data.zip\"\n",
    "if not os.path.isfile(output_directory + files_to_dl):\n",
    "    for file in files:\n",
    "        if file[\"name\"] == files_to_dl:\n",
    "            os.makedirs(output_directory, exist_ok=True)\n",
    "            urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 s, sys: 913 ms, total: 15.5 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with zipfile.ZipFile(os.path.join(output_directory, files_to_dl), \"r\") as f:\n",
    "    f.extractall(output_directory)\n",
    "os.remove(\"../data/observed_daily_rainfall_SYD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.4 s, sys: 5.73 s, total: 48.2 s\n",
      "Wall time: 51.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files = glob.glob(\"../data/*.csv\")\n",
    "columns = [\"time\", \"lat_min\", \"lat_max\", \"lon_min\", \"lon_max\", \"rain (mm/day)\"]\n",
    "df = pd.concat((pd.read_csv(file, index_col=0, usecols=columns)\n",
    "                .assign(model=re.findall(r\"[^\\/]+(?=\\_daily)\", file)[0])\n",
    "                for file in files)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.498125e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.251282e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-27 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.214660</td>\n",
       "      <td>153.1250</td>\n",
       "      <td>154.3750</td>\n",
       "      <td>6.689683e+00</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.214660</td>\n",
       "      <td>153.1250</td>\n",
       "      <td>154.3750</td>\n",
       "      <td>7.862555e+00</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.214660</td>\n",
       "      <td>153.1250</td>\n",
       "      <td>154.3750</td>\n",
       "      <td>1.000503e+01</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.214660</td>\n",
       "      <td>153.1250</td>\n",
       "      <td>154.3750</td>\n",
       "      <td>8.541592e+00</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.214660</td>\n",
       "      <td>153.1250</td>\n",
       "      <td>154.3750</td>\n",
       "      <td>6.811749e+01</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62467843 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lat_min    lat_max   lon_min   lon_max  rain (mm/day)  \\\n",
       "time                                                                           \n",
       "1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.244226e-13   \n",
       "1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.217326e-13   \n",
       "1889-01-03 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.498125e-13   \n",
       "1889-01-04 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.251282e-13   \n",
       "1889-01-05 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.270161e-13   \n",
       "...                        ...        ...       ...       ...            ...   \n",
       "2014-12-27 12:00:00 -30.157068 -29.214660  153.1250  154.3750   6.689683e+00   \n",
       "2014-12-28 12:00:00 -30.157068 -29.214660  153.1250  154.3750   7.862555e+00   \n",
       "2014-12-29 12:00:00 -30.157068 -29.214660  153.1250  154.3750   1.000503e+01   \n",
       "2014-12-30 12:00:00 -30.157068 -29.214660  153.1250  154.3750   8.541592e+00   \n",
       "2014-12-31 12:00:00 -30.157068 -29.214660  153.1250  154.3750   6.811749e+01   \n",
       "\n",
       "                               model  \n",
       "time                                  \n",
       "1889-01-01 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-02 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-03 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-04 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-05 12:00:00  MPI-ESM-1-2-HAM  \n",
       "...                              ...  \n",
       "2014-12-27 12:00:00      SAM0-UNICON  \n",
       "2014-12-28 12:00:00      SAM0-UNICON  \n",
       "2014-12-29 12:00:00      SAM0-UNICON  \n",
       "2014-12-30 12:00:00      SAM0-UNICON  \n",
       "2014-12-31 12:00:00      SAM0-UNICON  \n",
       "\n",
       "[62467843 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtimes of CSV compilation\n",
    "\n",
    "\n",
    "| Team Member | OS           | RAM | Processor        | Is SSD | Wall Time Taken |\n",
    "|-------------|--------------|-----|------------------|--------|-----------------|\n",
    "| Nikita      | Ubuntu 20.04 | 8GB | 8th Gen Core i7  | Yes    | 1min 32s        |\n",
    "| Margot      |              |     |                  |        |                 |\n",
    "| Thea        |              |     |                  |        |                 |\n",
    "| Kiran       |    MacOS Big Sur          |   8GB  |     Apple M1 chip            |    Yes    |        1min 40s         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to select which method is the most appropriate to transfer the dataframe from python to R, we chose to try all methods and observe which method was more suitable for us (the code and output of the methods that were not selected are placed in markdown cells):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "df.to_parquet(\"../data/rainfall.parquet\")\n",
    "\n",
    ">>> CPU times: user 22.3 s, sys: 5.77 s, total: 28.1 s\n",
    "Wall time: 30.1 s\n",
    "```\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "%%R\n",
    "library(dplyr)\n",
    "library(arrow)\n",
    "parquet_rdf <- read_parquet(\"../data/rainfall.parquet\") |> collect()\n",
    "\n",
    ">>> CPU times: user 4.42 s, sys: 4.37 s, total: 8.8 s\n",
    "Wall time: 8.37 s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feather Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "import pyarrow.feather as feather\n",
    "feather.write_feather(df, '../data/rainfall.feather')\n",
    "\n",
    ">>> CPU times: user 4.5 s, sys: 4.45 s, total: 8.95 s\n",
    "Wall time: 6.89 s\n",
    "```\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "%%R\n",
    "feather_rdf <- read_feather(\"../data/rainfall.feather\") |> collect()\n",
    "\n",
    ">>> CPU times: user 1.09 s, sys: 1.84 s, total: 2.93 s\n",
    "Wall time: 4.31 s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrow Exchange Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects.conversion\n",
    "import pyarrow\n",
    "import rpy2.rinterface\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.52 s, sys: 3.72 s, total: 9.24 s\n",
      "Wall time: 8.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "arrow_rframe = pyra.converter.py2rpy(pyarrow.Table.from_pandas(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.97 ms, sys: 8.38 ms, total: 13.3 ms\n",
      "Wall time: 20.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i arrow_rframe\n",
    "library(dplyr)\n",
    "arrow_rframe <- arrow_rframe |> collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking size of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666.979758"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 0\n",
    "for file in files:\n",
    "    b = os.path.getsize(file)\n",
    "    b += b\n",
    "b * 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716.238154"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(\"../data/rainfall.feather\")*1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701.2660629999999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(\"../data/rainfall.parquet\")*1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of different transfer methods:**\n",
    "\n",
    "\n",
    "| Method | Estimated time to transfer | File memory |\n",
    "| --- | --- | --- |\n",
    "| Arrow Exchange | 9s | 667 MB |\n",
    "| Feather file | 11s | 716 MB |\n",
    "| Parquet file | 27s | 701 MB |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justification:** The 'Arrow Exchange' method appeared to speed up the conversion of a pandas DataFrame into tabular data that is accessible for R. We opted for this method since it decreases the time spent during the serialization and de-serialization process while also avoiding the creation of unnecessary copies of the data. In addition to this, the file storage format appears to be slightly less memory-intensive compared to the other file storage formats. Altogether, the 'Arrow Exchange' method appeared to be the most appropriate for our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 62,467,843 × 7\n",
      "   lat_min lat_max lon_min lon_max `rain (mm/day)` model           time         \n",
      "     <dbl>   <dbl>   <dbl>   <dbl>           <dbl> <chr>           <chr>        \n",
      " 1   -35.4   -33.6    142.    143.        4.24e-13 MPI-ESM-1-2-HAM 1889-01-01 1…\n",
      " 2   -35.4   -33.6    142.    143.        4.22e-13 MPI-ESM-1-2-HAM 1889-01-02 1…\n",
      " 3   -35.4   -33.6    142.    143.        4.50e-13 MPI-ESM-1-2-HAM 1889-01-03 1…\n",
      " 4   -35.4   -33.6    142.    143.        4.25e-13 MPI-ESM-1-2-HAM 1889-01-04 1…\n",
      " 5   -35.4   -33.6    142.    143.        4.27e-13 MPI-ESM-1-2-HAM 1889-01-05 1…\n",
      " 6   -35.4   -33.6    142.    143.        4.20e-13 MPI-ESM-1-2-HAM 1889-01-06 1…\n",
      " 7   -35.4   -33.6    142.    143.        4.19e-13 MPI-ESM-1-2-HAM 1889-01-07 1…\n",
      " 8   -35.4   -33.6    142.    143.        4.56e-13 MPI-ESM-1-2-HAM 1889-01-08 1…\n",
      " 9   -35.4   -33.6    142.    143.        2.53e+ 0 MPI-ESM-1-2-HAM 1889-01-09 1…\n",
      "10   -35.4   -33.6    142.    143.        4.12e- 2 MPI-ESM-1-2-HAM 1889-01-10 1…\n",
      "# … with 62,467,833 more rows\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "arrow_rframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python [conda env:525_2022]",
   "language": "python",
   "name": "conda-env-525_2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
